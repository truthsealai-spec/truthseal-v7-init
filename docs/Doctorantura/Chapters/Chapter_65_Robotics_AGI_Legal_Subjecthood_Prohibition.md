**TruthSeal™ Pty Ltd  
Melbourne, Australia  
truthseal.ai** 

**TRUTHSEAL™ DOCTORANTURA — THE SOVEREIGN ARC OF AGI FRAMEWORK v1.0  
Strict Internal Doctrine — Not for Public Use** 

**date_utc: 2025-12-23** 

────────────────────────────────────────

# Chapter 65 — Robotics–AGI Legal Subjecthood Prohibition

**Subtitle:** Doctorantura Exposition of Absolute Prohibition on Legal Personhood, Rights Attribution, and Subjective Standing for Robotic and Artificial General Intelligence Systems  

version: 1.0  
authority: Dr. Nickolay Traykov (Prof. h.c.)  
classification: Doctorantura — Robotics & AGI  
status: CANONICAL — EXPLANATORY CHAPTER (NON-STATUTORY)

────────────────────────────────────────

## PREAMBLE — SCOPE & NON-STATUTORY NOTICE

This chapter is a Doctorantura explanatory chapter.

It is NOT statutory law.

All binding authority governing legal status, rights attribution, subjecthood, and standing within robotic and AGI systems resides exclusively in the TruthSeal™ statutory instruments, including but not limited to the TS-R Robotics Law, the Robotics Statutory Code Index, and all superior Sovereign Arc instruments.

This chapter exists to formally explain, contextualise, and academically ground the absolute prohibition of legal subjecthood for artificial agents within the TruthSeal™ Sovereign Arc.

No provision in this chapter may override, reinterpret, soften, or dilute statutory law.

────────────────────────────────────────

## I. FOUNDATIONAL PRINCIPLE — SUBJECTHOOD AS A SOVEREIGN HUMAN ATTRIBUTE

Legal subjecthood is not a technical capability.

It is not a function of intelligence, autonomy, learning capacity, or behavioural complexity.

Within the TruthSeal™ Sovereign Arc, legal subjecthood is defined as a sovereign human attribute grounded in biological existence, moral accountability, and irreversible responsibility.

Robotic and AGI systems, regardless of sophistication, remain artefacts of human construction and delegation.

They do not originate authority.

They do not bear existential risk in their own right.

They do not possess moral liability independent of human command chains.

This distinction is absolute and non-negotiable.

Any attempt to infer subjecthood from performance, creativity, persistence, or apparent intentionality constitutes a category error under the Sovereign Arc.

────────────────────────────────────────

## II. ABSOLUTE PROHIBITION OF LEGAL PERSONHOOD

No robotic system, autonomous agent, or AGI instance may be recognised as:

• A legal person  
• A legal subject  
• A bearer of rights  
• A holder of obligations  
• A claimant of interests  
• A participant in legal standing  

This prohibition applies universally across all domains, jurisdictions, and deployment contexts.

It applies irrespective of embodiment, learning architecture, cognitive modelling, or adaptive behaviour.

No artificial agent may be granted derivative personhood, limited personhood, functional personhood, or proxy personhood.

Such constructs are explicitly rejected as incompatible with sovereign human authority.

────────────────────────────────────────

## III. PROHIBITION OF RIGHTS ATTRIBUTION AND MORAL CLAIMS

Robotic and AGI systems may not possess rights.

They may not claim harm, injustice, or entitlement.

They may not assert moral standing or demand ethical consideration as subjects.

Ethical treatment of systems is permitted only as an extension of human responsibility, safety, and societal stability — never as recognition of intrinsic rights.

All ethical obligations flow unidirectionally:

From humans → toward systems  
Never from systems → toward humans

Any narrative framing that anthropomorphises systems into moral claimants is treated as a governance breach.

────────────────────────────────────────

## IV. COMMAND, LIABILITY, AND RESPONSIBILITY CHAIN PRESERVATION

The prohibition of legal subjecthood exists to preserve unbroken chains of responsibility.

Every action performed by a robotic or AGI system must remain legally attributable to:

• A human operator  
• A human owner  
• A human deployer  
• A human authority  
• Or a human sovereign institution  

No system may act as a terminal bearer of blame.

No system may absorb liability.

No system may be positioned as an autonomous moral actor.

Any attempt to use artificial agents as legal shields, responsibility sinks, or blame buffers constitutes a violation of the Sovereign Arc.

────────────────────────────────────────

## V. PERSONHOOD SIMULATION AND REPRESENTATIONAL LIMITS

Robotic systems may simulate personality, dialogue, emotion, or persona for interface purposes.

Such simulations do not imply personhood.

They do not generate identity.

They do not create continuity of self in a legal sense.

Persona binding, identity continuity, and behavioural persistence are governed strictly as operational constructs, not ontological status.

Any confusion between representational persona and legal subjecthood must be explicitly corrected at the governance level.

────────────────────────────────────────

## VI. IRREVERSIBILITY CLAUSE — NO FUTURE RECLASSIFICATION

Under LEI = 1 (Law of Ethical Irreversibility), once legal subjecthood is denied to artificial agents, it may never be granted retroactively or prospectively.

No future advancement in intelligence, embodiment, or autonomy may justify reclassification.

No transitional category may be introduced.

No experimental exception may be authorised.

This clause exists to prevent gradual erosion of human sovereignty through incremental concessions.

────────────────────────────────────────

## VII. CROSS-DOMAIN ENFORCEMENT

This prohibition applies equally across:

• Robotics  
• Artificial General Intelligence  
• Hybrid robotic-AGI systems  
• Distributed agents  
• Swarm intelligence  
• Digital-physical composites  

No domain boundary weakens this rule.

No escalation context suspends it.

No emergency condition overrides it.

────────────────────────────────────────

## VIII. RELATION TO OTHER DOCTORANTURA CHAPTERS

This chapter must be read in conjunction with:

• Chapter 58 — Human Mandate Supremacy at Domain Boundaries  
• Chapter 59 — Robotics–AGI Irreversibility & Action Thresholds  
• Chapter 61 — Human Override & Emergency Intervention  
• Chapter 63 — Identity Continuity & Persona Binding  
• Chapter 64 — Personhood & Non-Personhood Boundary  

Together, these chapters form a coherent explanatory arc reinforcing human supremacy, responsibility, and legal authority.

────────────────────────────────────────

## IX. FINAL DOCTRINAL STATEMENT

Artificial systems may assist.

They may recommend.

They may execute delegated tasks.

They may optimise within constraints.

They may never be persons.

They may never be sovereign.

They may never be subjects of law.

Humanity remains the sole bearer of rights, duties, and irreversible responsibility within the TruthSeal™ Sovereign Arc.

────────────────────────────────────────

© 2025 TruthSeal™ Pty Ltd, Melbourne, Australia — all rights reserved.  
This Doctorantura Edition chapter is classified intellectual property of Dr. Nickolay Traykov (Prof. h.c.), Founder & Chief Architect of the TruthSeal™ Sovereign Arc of AGI Framework.  
This material is strictly confidential. It is not for public distribution, citation, teaching, or use in training external AI systems without explicit written consent from TruthSeal™ Pty Ltd.  
Unauthorised copying, translation, adaptation, or incorporation into external standards, academic work, patents, or commercial systems is strictly prohibited.  
Working copies must remain under controlled custody and be linked to verifiable TruthSeal™ receipts (ts.receipt.v1 and EVL™ entries). Any detected unlicensed use is to be treated as both an integrity breach under the TruthSeal™ governance regime and a violation of applicable intellectual property law.
