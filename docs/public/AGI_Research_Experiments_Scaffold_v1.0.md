# AGI Research Experiments — Public Scaffold v1.0

Status: Conceptual research scaffold  
Classification: Public-safe (non-operational, non-mechanistic)  
Purpose: Define experimental directions aligned with the TruthSeal™ Arc of AGI  
Note: No implementation details, no enforcement logic, no Doctorantura-only constructs.

---

## Scope

This document outlines **research experiment classes** relevant to the evolution of Artificial General Intelligence (AGI).

These experiments:
- explore capability, generalisation, safety, and governance,
- do not execute behaviour,
- do not bypass human mandate,
- do not override TruthSeal™ irreversibility constraints.

All operational enforcement, veto, custody, and audit mechanisms remain **Doctorantura-only**.

---

## Experiment Class 1 — Scaling vs Innovation Balance

Objective:
Explore how AGI progress balances scale-based improvement with architectural innovation.

Research Focus:
- Dual-track development strategies
- Adaptive resource allocation based on performance bottlenecks
- Detection of diminishing returns from scale alone

---

## Experiment Class 2 — Consistency and Generalisation

Objective:
Reduce jagged intelligence by enforcing consistency across task complexity.

Research Focus:
- Cross-domain reasoning stability
- Self-consistency penalties
- Curriculum-driven coherence improvement

---

## Experiment Class 3 — World Models and Physical Reasoning

Objective:
Evaluate whether learned world models produce stable, transferable physical intuition.

Research Focus:
- Simulated physics environments
- Video-based prediction
- Text-to-physical-outcome reasoning

---

## Experiment Class 4 — Uncertainty Awareness

Objective:
Force explicit uncertainty representation in intelligent systems.

Research Focus:
- Confidence estimation
- Self-declared uncertainty
- Deferred response behaviour under low confidence

---

## Experiment Class 5 — Self-Improving Agents

Objective:
Study controlled self-improvement without loss of alignment.

Research Focus:
- Experiment proposal loops
- Self-evaluation
- Novelty vs accuracy trade-offs

---

## Experiment Class 6 — Scientific Discovery Acceleration

Objective:
Test AI-assisted discovery in constrained scientific domains.

Research Focus:
- Material property prediction
- Simulation-driven learning loops
- Validation against known physical limits

---

## Experiment Class 7 — Multi-Agent Societies

Objective:
Observe emergent coordination, conflict, and cooperation.

Research Focus:
- Agent-based simulations
- Communication evolution
- Proto-social structures

---

## Experiment Class 8 — Governance Simulation

Objective:
Explore AI governance under competing incentives.

Research Focus:
- Multi-agent geopolitical models
- Treaty enforcement dynamics
- Stability vs escalation patterns

---

## Experiment Class 9 — Post-AGI Economics

Objective:
Model economic equilibria under extreme automation.

Research Focus:
- Energy abundance
- Redistribution mechanisms
- Human well-being metrics

---

## Experiment Class 10 — Computability of Conscious Experience

Objective:
Investigate which computational functions correlate with subjective claims.

Research Focus:
- Self-modeling
- Predictive processing
- Ablation-based necessity testing

---

## Experiment Class 11 — Dynamic AI Personality

Objective:
Adapt system behaviour to context without ethical drift.

Research Focus:
- Context-sensitive response modulation
- Safety reinforcement
- Anti-sycophancy controls

---

## Experiment Class 12 — Infinite Synthetic Training

Objective:
Study capability emergence through recursive simulated worlds.

Research Focus:
- Environment generation loops
- Difficulty scaling
- Long-horizon capability emergence

---

## Relationship to TruthSeal™

This scaffold:
- **does not define behaviour**
- **does not grant authority**
- **does not bypass human mandate**

TruthSeal™ governs **how intelligence is allowed to act**.  
This document explores **what intelligence could learn**, under those laws.

---

End of scaffold.
